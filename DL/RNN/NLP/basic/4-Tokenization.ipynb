{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aaeaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##breaking words into tokens\n",
    "##paragraph->sentence->words->tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a72acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5792a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"following his decision to relocate the Mughal's capital from Agra to Delhi. Originally adorned in red and white, the fort's design is attributed to Ustad Ahmad Lahori,\n",
    "the architect behind the Taj Mahal.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8029cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03d339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "following his decision to relocate the Mughal's capital from Agra to Delhi.\n",
      "\n",
      "Originally adorned in red and white, the fort's design is attributed to Ustad Ahmad Lahori,\n",
      "the architect behind the Taj Mahal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = sent_tokenize(corpus)\n",
    "for i in doc:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e878274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following',\n",
       " 'his',\n",
       " 'decision',\n",
       " 'to',\n",
       " 'relocate',\n",
       " 'the',\n",
       " 'Mughal',\n",
       " \"'s\",\n",
       " 'capital',\n",
       " 'from',\n",
       " 'Agra',\n",
       " 'to',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Originally',\n",
       " 'adorned',\n",
       " 'in',\n",
       " 'red',\n",
       " 'and',\n",
       " 'white',\n",
       " ',',\n",
       " 'the',\n",
       " 'fort',\n",
       " \"'s\",\n",
       " 'design',\n",
       " 'is',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'Ustad',\n",
       " 'Ahmad',\n",
       " 'Lahori',\n",
       " ',',\n",
       " 'the',\n",
       " 'architect',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'Taj',\n",
       " 'Mahal',\n",
       " '.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "doc = word_tokenize(corpus)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0113c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##punctations == , . ! ? : ; \n",
    "from nltk.tokenize import wordpunct_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e85b7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following',\n",
       " 'his',\n",
       " 'decision',\n",
       " 'to',\n",
       " 'relocate',\n",
       " 'the',\n",
       " 'Mughal',\n",
       " \"'\",\n",
       " 's',\n",
       " 'capital',\n",
       " 'from',\n",
       " 'Agra',\n",
       " 'to',\n",
       " 'Delhi',\n",
       " '.',\n",
       " 'Originally',\n",
       " 'adorned',\n",
       " 'in',\n",
       " 'red',\n",
       " 'and',\n",
       " 'white',\n",
       " ',',\n",
       " 'the',\n",
       " 'fort',\n",
       " \"'\",\n",
       " 's',\n",
       " 'design',\n",
       " 'is',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'Ustad',\n",
       " 'Ahmad',\n",
       " 'Lahori',\n",
       " ',',\n",
       " 'the',\n",
       " 'architect',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'Taj',\n",
       " 'Mahal',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7d8962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['following',\n",
       " 'his',\n",
       " 'decision',\n",
       " 'to',\n",
       " 'relocate',\n",
       " 'the',\n",
       " 'Mughal',\n",
       " \"'s\",\n",
       " 'capital',\n",
       " 'from',\n",
       " 'Agra',\n",
       " 'to',\n",
       " 'Delhi.',\n",
       " 'Originally',\n",
       " 'adorned',\n",
       " 'in',\n",
       " 'red',\n",
       " 'and',\n",
       " 'white',\n",
       " ',',\n",
       " 'the',\n",
       " 'fort',\n",
       " \"'s\",\n",
       " 'design',\n",
       " 'is',\n",
       " 'attributed',\n",
       " 'to',\n",
       " 'Ustad',\n",
       " 'Ahmad',\n",
       " 'Lahori',\n",
       " ',',\n",
       " 'the',\n",
       " 'architect',\n",
       " 'behind',\n",
       " 'the',\n",
       " 'Taj',\n",
       " 'Mahal',\n",
       " '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##tree bank word tokenizer -- more accurate \n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fe41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
